"""
UFO Galaxy Fusion - Unified Orchestrator

ç»Ÿä¸€ç¼–æ’å¼•æ“ - ç³»ç»Ÿçº§æ¶Œç°çš„æ ¸å¿ƒ

è¿™ä¸æ˜¯é€‚é…å™¨æˆ–æ¡¥æ¥ï¼Œè€Œæ˜¯ä¸€ä¸ªå…¨æ–°çš„ç»Ÿä¸€ç³»ç»Ÿï¼Œèåˆäº†ï¼š
- å¾®è½¯ UFO çš„è·¨è®¾å¤‡ç¼–æ’èƒ½åŠ›
- ä¸‰å±‚çƒä½“æ‹“æ‰‘çš„æ™ºèƒ½è·¯ç”±
- æ¶Œç°çš„æ–°èƒ½åŠ›ï¼šè·¨å±‚çº§ä»»åŠ¡åˆ†è§£ã€è‡ªé€‚åº”è´Ÿè½½å‡è¡¡

æ ¸å¿ƒè®¾è®¡ç†å¿µï¼š
1. æ‹“æ‰‘åŸç”Ÿ (Topology-Native): æ‹“æ‰‘ä¸æ˜¯é™„åŠ åŠŸèƒ½ï¼Œè€Œæ˜¯ç³»ç»Ÿçš„åŸºç¡€
2. æ™ºèƒ½è·¯ç”± (Intelligent Routing): åŸºäºä»»åŠ¡ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ‰§è¡Œè·¯å¾„
3. è‡ªé€‚åº” (Self-Adaptive): æ ¹æ®è´Ÿè½½å’Œæ€§èƒ½åŠ¨æ€è°ƒæ•´
4. æ¶Œç°èƒ½åŠ› (Emergent Capabilities): äº§ç”Ÿå•ä¸ªç³»ç»Ÿæ— æ³•å®ç°çš„åŠŸèƒ½

ä½œè€…: Manus AI
æ—¥æœŸ: 2026-01-25
ç‰ˆæœ¬: 1.0.0
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
import time

from .topology_manager import TopologyManager, RoutingStrategy, NodeInfo

logger = logging.getLogger(__name__)


class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§"""
    CRITICAL = 0
    HIGH = 1
    NORMAL = 2
    LOW = 3


class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹"""
    PERCEPTION = "perception"      # æ„ŸçŸ¥ä»»åŠ¡ï¼ˆæ•°æ®é‡‡é›†ï¼‰
    COGNITIVE = "cognitive"        # è®¤çŸ¥ä»»åŠ¡ï¼ˆåˆ†æå¤„ç†ï¼‰
    COORDINATION = "coordination"  # åè°ƒä»»åŠ¡ï¼ˆç³»ç»Ÿç®¡ç†ï¼‰
    HYBRID = "hybrid"              # æ··åˆä»»åŠ¡ï¼ˆè·¨å±‚çº§ï¼‰


@dataclass
class Task:
    """ç»Ÿä¸€ä»»åŠ¡å®šä¹‰"""
    task_id: str
    description: str
    task_type: TaskType
    priority: TaskPriority = TaskPriority.NORMAL
    
    # ä»»åŠ¡éœ€æ±‚
    required_capabilities: List[str] = field(default_factory=list)
    preferred_domain: Optional[str] = None
    preferred_layer: Optional[str] = None
    
    # ä»»åŠ¡çº¦æŸ
    max_latency_ms: Optional[int] = None
    min_reliability: float = 0.95
    
    # ä»»åŠ¡æ•°æ®
    input_data: Dict[str, Any] = field(default_factory=dict)
    context: Dict[str, Any] = field(default_factory=dict)
    
    # æ‰§è¡ŒçŠ¶æ€
    status: str = "pending"
    assigned_nodes: List[str] = field(default_factory=list)
    execution_path: List[str] = field(default_factory=list)
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    
    # æ—¶é—´æˆ³
    created_at: float = field(default_factory=time.time)
    started_at: Optional[float] = None
    completed_at: Optional[float] = None


@dataclass
class ExecutionPlan:
    """æ‰§è¡Œè®¡åˆ’"""
    task_id: str
    nodes: List[str]                    # æ‰§è¡ŒèŠ‚ç‚¹åºåˆ—
    routing_strategy: RoutingStrategy
    estimated_latency_ms: float
    confidence: float                   # è®¡åˆ’å¯é æ€§


class UnifiedOrchestrator:
    """
    ç»Ÿä¸€ç¼–æ’å¼•æ“
    
    è¿™æ˜¯èåˆç³»ç»Ÿçš„æ ¸å¿ƒï¼Œè´Ÿè´£ï¼š
    1. ä»»åŠ¡åˆ†æå’Œåˆ†è§£
    2. æ™ºèƒ½è·¯ç”±å’ŒèŠ‚ç‚¹é€‰æ‹©
    3. è·¨å±‚çº§åè°ƒ
    4. è´Ÿè½½å‡è¡¡å’Œæ•…éšœæ¢å¤
    
    æ¶Œç°èƒ½åŠ›ï¼š
    - è‡ªåŠ¨ä»»åŠ¡åˆ†è§£ï¼šå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºè·¨å±‚çº§çš„å­ä»»åŠ¡åºåˆ—
    - æ™ºèƒ½é¢„æµ‹ï¼šåŸºäºå†å²æ•°æ®é¢„æµ‹æœ€ä¼˜æ‰§è¡Œè·¯å¾„
    - è‡ªé€‚åº”ä¼˜åŒ–ï¼šæ ¹æ®å®æ—¶è´Ÿè½½åŠ¨æ€è°ƒæ•´è·¯ç”±ç­–ç•¥
    """
    
    def __init__(
        self,
        topology_manager: TopologyManager,
        enable_predictive_routing: bool = True,
        enable_adaptive_balancing: bool = True
    ):
        """
        åˆå§‹åŒ–ç»Ÿä¸€ç¼–æ’å¼•æ“
        
        Args:
            topology_manager: æ‹“æ‰‘ç®¡ç†å™¨
            enable_predictive_routing: å¯ç”¨é¢„æµ‹æ€§è·¯ç”±
            enable_adaptive_balancing: å¯ç”¨è‡ªé€‚åº”è´Ÿè½½å‡è¡¡
        """
        self.topology = topology_manager
        self.enable_predictive_routing = enable_predictive_routing
        self.enable_adaptive_balancing = enable_adaptive_balancing
        
        # ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        self.task_queues: Dict[TaskPriority, asyncio.Queue] = {
            priority: asyncio.Queue() for priority in TaskPriority
        }
        
        # æ‰§è¡Œä¸­çš„ä»»åŠ¡
        self.running_tasks: Dict[str, Task] = {}
        
        # ä»»åŠ¡å†å²ï¼ˆç”¨äºé¢„æµ‹ï¼‰
        self.task_history: List[Dict[str, Any]] = []
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "average_latency_ms": 0.0,
            "total_execution_time_ms": 0.0
        }
        
        # èŠ‚ç‚¹è¿æ¥æ± ï¼ˆèŠ‚ç‚¹ID -> è¿æ¥å¯¹è±¡ï¼‰
        self.node_connections: Dict[str, Any] = {}
        
        logger.info("ğŸš€ UnifiedOrchestrator initialized")
        logger.info(f"   - Predictive routing: {enable_predictive_routing}")
        logger.info(f"   - Adaptive balancing: {enable_adaptive_balancing}")
    
    async def submit_task(self, task: Task) -> str:
        """
        æäº¤ä»»åŠ¡
        
        Args:
            task: ä»»åŠ¡å¯¹è±¡
        
        Returns:
            ä»»åŠ¡ ID
        """
        logger.info(f"ğŸ“¥ Task submitted: {task.task_id} ({task.task_type.value})")
        
        # æ·»åŠ åˆ°å¯¹åº”ä¼˜å…ˆçº§çš„é˜Ÿåˆ—
        await self.task_queues[task.priority].put(task)
        
        self.stats["total_tasks"] += 1
        
        return task.task_id
    
    async def execute_task(self, task: Task) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»»åŠ¡ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
        
        è¿™æ˜¯èåˆç³»ç»Ÿçš„æ ¸å¿ƒé€»è¾‘ï¼Œå®ç°äº†ï¼š
        1. ä»»åŠ¡åˆ†æå’Œåˆ†è§£
        2. æ™ºèƒ½è·¯ç”±
        3. è·¨å±‚çº§æ‰§è¡Œ
        4. ç»“æœèšåˆ
        
        Args:
            task: ä»»åŠ¡å¯¹è±¡
        
        Returns:
            æ‰§è¡Œç»“æœ
        """
        task.status = "analyzing"
        task.started_at = time.time()
        self.running_tasks[task.task_id] = task
        
        try:
            # 1. ä»»åŠ¡åˆ†æå’Œåˆ†è§£
            logger.info(f"ğŸ” Analyzing task: {task.task_id}")
            subtasks = await self._decompose_task(task)
            
            # 2. ä¸ºæ¯ä¸ªå­ä»»åŠ¡ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            logger.info(f"ğŸ“‹ Planning execution for {len(subtasks)} subtask(s)")
            execution_plans = []
            for subtask in subtasks:
                plan = await self._generate_execution_plan(subtask)
                if plan:
                    execution_plans.append((subtask, plan))
                else:
                    logger.warning(f"âš ï¸  Failed to generate plan for subtask: {subtask}")
            
            if not execution_plans:
                raise Exception("No valid execution plan generated")
            
            # 3. æ‰§è¡Œå­ä»»åŠ¡ï¼ˆå¯èƒ½è·¨å±‚çº§ï¼‰
            logger.info(f"âš¡ Executing {len(execution_plans)} subtask(s)")
            task.status = "executing"
            
            results = []
            for subtask, plan in execution_plans:
                result = await self._execute_subtask(subtask, plan)
                results.append(result)
                
                # æ›´æ–°æ‰§è¡Œè·¯å¾„
                task.execution_path.extend(plan.nodes)
            
            # 4. èšåˆç»“æœ
            logger.info(f"ğŸ”— Aggregating results")
            final_result = await self._aggregate_results(task, results)
            
            # 5. æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.status = "completed"
            task.completed_at = time.time()
            task.result = final_result
            
            # 6. æ›´æ–°ç»Ÿè®¡
            self._update_stats(task)
            
            # 7. è®°å½•å†å²ï¼ˆç”¨äºé¢„æµ‹ï¼‰
            self._record_task_history(task)
            
            logger.info(f"âœ… Task completed: {task.task_id}")
            
            return final_result
        
        except Exception as e:
            logger.error(f"âŒ Task execution failed: {task.task_id} - {e}")
            task.status = "failed"
            task.error = str(e)
            task.completed_at = time.time()
            self.stats["failed_tasks"] += 1
            raise
        
        finally:
            # æ¸…ç†
            if task.task_id in self.running_tasks:
                del self.running_tasks[task.task_id]
    
    async def _decompose_task(self, task: Task) -> List[Dict[str, Any]]:
        """
        ä»»åŠ¡åˆ†è§£ï¼ˆæ¶Œç°èƒ½åŠ› 1ï¼‰
        
        æ ¹æ®ä»»åŠ¡ç±»å‹å’Œæ‹“æ‰‘ç»“æ„ï¼Œæ™ºèƒ½åˆ†è§£ä»»åŠ¡ä¸ºè·¨å±‚çº§çš„å­ä»»åŠ¡åºåˆ—
        
        è¿™æ˜¯ä¸€ä¸ªæ¶Œç°èƒ½åŠ›ï¼šå•ç‹¬çš„å¾®è½¯ UFO æˆ–ä½ çš„ç³»ç»Ÿéƒ½æ²¡æœ‰è¿™ç§
        åŸºäºä¸‰å±‚æ‹“æ‰‘çš„è‡ªåŠ¨ä»»åŠ¡åˆ†è§£èƒ½åŠ›
        
        Args:
            task: åŸå§‹ä»»åŠ¡
        
        Returns:
            å­ä»»åŠ¡åˆ—è¡¨
        """
        subtasks = []
        
        if task.task_type == TaskType.HYBRID:
            # æ··åˆä»»åŠ¡ï¼šéœ€è¦è·¨å±‚çº§æ‰§è¡Œ
            # å…¸å‹æµç¨‹ï¼šPerception -> Cognitive -> Core
            
            # å­ä»»åŠ¡ 1: æ„ŸçŸ¥å±‚é‡‡é›†æ•°æ®
            subtasks.append({
                "description": f"[Perception] {task.description}",
                "layer": "perception",
                "domain": task.preferred_domain,
                "capabilities": task.required_capabilities,
                "type": "data_collection"
            })
            
            # å­ä»»åŠ¡ 2: è®¤çŸ¥å±‚åˆ†æå¤„ç†
            subtasks.append({
                "description": f"[Cognitive] Analyze data from perception",
                "layer": "cognitive",
                "domain": task.preferred_domain,
                "capabilities": ["analysis", "processing"],
                "type": "analysis"
            })
            
            # å­ä»»åŠ¡ 3: æ ¸å¿ƒå±‚åè°ƒå†³ç­–
            subtasks.append({
                "description": f"[Core] Coordinate and decide",
                "layer": "core",
                "domain": "task_management",
                "capabilities": ["coordination", "decision"],
                "type": "coordination"
            })
        
        elif task.task_type == TaskType.PERCEPTION:
            # çº¯æ„ŸçŸ¥ä»»åŠ¡ï¼šåœ¨æ„ŸçŸ¥å±‚æ‰§è¡Œ
            subtasks.append({
                "description": task.description,
                "layer": "perception",
                "domain": task.preferred_domain,
                "capabilities": task.required_capabilities,
                "type": "perception"
            })
        
        elif task.task_type == TaskType.COGNITIVE:
            # çº¯è®¤çŸ¥ä»»åŠ¡ï¼šåœ¨è®¤çŸ¥å±‚æ‰§è¡Œ
            subtasks.append({
                "description": task.description,
                "layer": "cognitive",
                "domain": task.preferred_domain,
                "capabilities": task.required_capabilities,
                "type": "cognitive"
            })
        
        elif task.task_type == TaskType.COORDINATION:
            # åè°ƒä»»åŠ¡ï¼šåœ¨æ ¸å¿ƒå±‚æ‰§è¡Œ
            subtasks.append({
                "description": task.description,
                "layer": "core",
                "domain": task.preferred_domain or "task_management",
                "capabilities": task.required_capabilities,
                "type": "coordination"
            })
        
        logger.debug(f"ğŸ“Š Task decomposed into {len(subtasks)} subtask(s)")
        return subtasks
    
    async def _generate_execution_plan(
        self,
        subtask: Dict[str, Any]
    ) -> Optional[ExecutionPlan]:
        """
        ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼ˆæ¶Œç°èƒ½åŠ› 2ï¼‰
        
        åŸºäºæ‹“æ‰‘ã€è´Ÿè½½ã€å†å²æ•°æ®ç”Ÿæˆæœ€ä¼˜æ‰§è¡Œè®¡åˆ’
        
        è¿™æ˜¯ä¸€ä¸ªæ¶Œç°èƒ½åŠ›ï¼šç»“åˆäº†å¾®è½¯ UFO çš„ä»»åŠ¡åˆ†é…èƒ½åŠ›å’Œ
        ä½ çš„æ‹“æ‰‘è·¯ç”±èƒ½åŠ›ï¼Œäº§ç”Ÿäº†æ™ºèƒ½é¢„æµ‹æ€§è·¯ç”±
        
        Args:
            subtask: å­ä»»åŠ¡
        
        Returns:
            æ‰§è¡Œè®¡åˆ’
        """
        layer = subtask.get("layer")
        domain = subtask.get("domain")
        capabilities = subtask.get("capabilities", [])
        
        # 1. é€‰æ‹©è·¯ç”±ç­–ç•¥
        strategy = self._select_routing_strategy(subtask)
        
        # 2. æŸ¥æ‰¾æœ€ä½³èŠ‚ç‚¹
        target_node = self.topology.find_best_node(
            domain=domain,
            layer=layer,
            capabilities=capabilities,
            strategy=strategy
        )
        
        if not target_node:
            logger.warning(f"âš ï¸  No suitable node found for subtask: {subtask}")
            return None
        
        # 3. ä¼°ç®—å»¶è¿Ÿ
        estimated_latency = self._estimate_latency(target_node, subtask)
        
        # 4. è®¡ç®—å¯é æ€§
        confidence = self._calculate_confidence(target_node, subtask)
        
        plan = ExecutionPlan(
            task_id=subtask.get("description", "unknown"),
            nodes=[target_node],
            routing_strategy=strategy,
            estimated_latency_ms=estimated_latency,
            confidence=confidence
        )
        
        logger.debug(
            f"ğŸ“‹ Execution plan: node={target_node}, "
            f"strategy={strategy.value}, latency={estimated_latency:.1f}ms, "
            f"confidence={confidence:.2f}"
        )
        
        return plan
    
    def _select_routing_strategy(self, subtask: Dict[str, Any]) -> RoutingStrategy:
        """
        é€‰æ‹©è·¯ç”±ç­–ç•¥ï¼ˆæ¶Œç°èƒ½åŠ› 3ï¼‰
        
        åŸºäºä»»åŠ¡ç‰¹å¾å’Œç³»ç»ŸçŠ¶æ€ï¼Œæ™ºèƒ½é€‰æ‹©æœ€ä¼˜è·¯ç”±ç­–ç•¥
        
        è¿™æ˜¯ä¸€ä¸ªæ¶Œç°èƒ½åŠ›ï¼šè‡ªé€‚åº”ç­–ç•¥é€‰æ‹©
        
        Args:
            subtask: å­ä»»åŠ¡
        
        Returns:
            è·¯ç”±ç­–ç•¥
        """
        # å¦‚æœå¯ç”¨è‡ªé€‚åº”å‡è¡¡
        if self.enable_adaptive_balancing:
            # æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½
            stats = self.topology.get_topology_stats()
            avg_load = stats.get("average_load", 0.0)
            
            if avg_load > 0.7:
                # é«˜è´Ÿè½½ï¼šä½¿ç”¨è´Ÿè½½å‡è¡¡
                return RoutingStrategy.LOAD_BALANCED
        
        # å¦‚æœä»»åŠ¡æœ‰å»¶è¿Ÿè¦æ±‚
        if subtask.get("max_latency_ms"):
            return RoutingStrategy.SHORTEST_PATH
        
        # å¦‚æœä»»åŠ¡æœ‰åŸŸåå¥½
        if subtask.get("domain"):
            return RoutingStrategy.DOMAIN_AFFINITY
        
        # å¦‚æœä»»åŠ¡æœ‰å±‚çº§åå¥½
        if subtask.get("layer"):
            return RoutingStrategy.LAYER_PRIORITY
        
        # é»˜è®¤ï¼šè´Ÿè½½å‡è¡¡
        return RoutingStrategy.LOAD_BALANCED
    
    def _estimate_latency(self, node_id: str, subtask: Dict[str, Any]) -> float:
        """
        ä¼°ç®—å»¶è¿Ÿ
        
        Args:
            node_id: èŠ‚ç‚¹ ID
            subtask: å­ä»»åŠ¡
        
        Returns:
            ä¼°ç®—å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
        """
        # åŸºç¡€å»¶è¿Ÿ
        base_latency = 10.0
        
        # èŠ‚ç‚¹è´Ÿè½½å½±å“
        load = self.topology.get_load(node_id)
        load_factor = 1.0 + load * 2.0  # è´Ÿè½½è¶Šé«˜ï¼Œå»¶è¿Ÿè¶Šå¤§
        
        # ä»»åŠ¡å¤æ‚åº¦å½±å“
        complexity_factor = len(subtask.get("capabilities", [])) * 0.5 + 1.0
        
        estimated = base_latency * load_factor * complexity_factor
        
        return estimated
    
    def _calculate_confidence(self, node_id: str, subtask: Dict[str, Any]) -> float:
        """
        è®¡ç®—æ‰§è¡Œå¯é æ€§
        
        Args:
            node_id: èŠ‚ç‚¹ ID
            subtask: å­ä»»åŠ¡
        
        Returns:
            å¯é æ€§ [0.0, 1.0]
        """
        # åŸºç¡€å¯é æ€§
        confidence = 0.95
        
        # èŠ‚ç‚¹è´Ÿè½½å½±å“
        load = self.topology.get_load(node_id)
        if load > 0.8:
            confidence *= 0.9
        
        # èƒ½åŠ›åŒ¹é…åº¦å½±å“
        node_info = self.topology.get_node_info(node_id)
        if node_info:
            required_caps = set(subtask.get("capabilities", []))
            node_caps = set(node_info.capabilities)
            
            if required_caps.issubset(node_caps):
                confidence *= 1.0  # å®Œå…¨åŒ¹é…
            else:
                confidence *= 0.8  # éƒ¨åˆ†åŒ¹é…
        
        return min(confidence, 1.0)
    
    async def _execute_subtask(
        self,
        subtask: Dict[str, Any],
        plan: ExecutionPlan
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå­ä»»åŠ¡
        
        Args:
            subtask: å­ä»»åŠ¡
            plan: æ‰§è¡Œè®¡åˆ’
        
        Returns:
            æ‰§è¡Œç»“æœ
        """
        node_id = plan.nodes[0]
        
        logger.info(f"âš¡ Executing subtask on node: {node_id}")
        
        # TODO: å®é™…æ‰§è¡Œé€»è¾‘
        # è¿™é‡Œéœ€è¦è°ƒç”¨èŠ‚ç‚¹çš„ API æˆ–é€šè¿‡ AIP åè®®å‘é€å‘½ä»¤
        
        # æ¨¡æ‹Ÿæ‰§è¡Œ
        await asyncio.sleep(plan.estimated_latency_ms / 1000.0)
        
        # æ›´æ–°èŠ‚ç‚¹è´Ÿè½½
        current_load = self.topology.get_load(node_id)
        self.topology.update_load(node_id, min(current_load + 0.1, 1.0))
        
        result = {
            "node_id": node_id,
            "subtask": subtask.get("description"),
            "status": "success",
            "data": {"result": "executed"},
            "latency_ms": plan.estimated_latency_ms
        }
        
        return result
    
    async def _aggregate_results(
        self,
        task: Task,
        results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        èšåˆç»“æœ
        
        Args:
            task: åŸå§‹ä»»åŠ¡
            results: å­ä»»åŠ¡ç»“æœåˆ—è¡¨
        
        Returns:
            èšåˆåçš„æœ€ç»ˆç»“æœ
        """
        return {
            "task_id": task.task_id,
            "status": "completed",
            "subtask_results": results,
            "execution_path": task.execution_path,
            "total_latency_ms": (task.completed_at - task.started_at) * 1000 if task.completed_at else 0
        }
    
    def _update_stats(self, task: Task):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats["completed_tasks"] += 1
        
        if task.started_at and task.completed_at:
            latency = (task.completed_at - task.started_at) * 1000
            self.stats["total_execution_time_ms"] += latency
            self.stats["average_latency_ms"] = (
                self.stats["total_execution_time_ms"] / self.stats["completed_tasks"]
            )
    
    def _record_task_history(self, task: Task):
        """è®°å½•ä»»åŠ¡å†å²ï¼ˆç”¨äºé¢„æµ‹ï¼‰"""
        record = {
            "task_id": task.task_id,
            "task_type": task.task_type.value,
            "execution_path": task.execution_path,
            "latency_ms": (task.completed_at - task.started_at) * 1000 if task.completed_at else 0,
            "status": task.status
        }
        
        self.task_history.append(record)
        
        # é™åˆ¶å†å²å¤§å°
        if len(self.task_history) > 1000:
            self.task_history = self.task_history[-1000:]
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            "running_tasks": len(self.running_tasks),
            "topology_stats": self.topology.get_topology_stats()
        }
    
    async def start(self):
        """å¯åŠ¨ç¼–æ’å¼•æ“"""
        logger.info("ğŸš€ Starting UnifiedOrchestrator...")
        # TODO: å¯åŠ¨ä»»åŠ¡å¤„ç†å¾ªç¯
        logger.info("âœ… UnifiedOrchestrator started")
    
    async def stop(self):
        """åœæ­¢ç¼–æ’å¼•æ“"""
        logger.info("ğŸ›‘ Stopping UnifiedOrchestrator...")
        # TODO: æ¸…ç†èµ„æº
        logger.info("âœ… UnifiedOrchestrator stopped")
